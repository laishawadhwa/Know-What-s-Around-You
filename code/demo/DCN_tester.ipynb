{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path='/dip_project/'\n",
    "opt = {\n",
    "    'data_info': base_path + 'data/cocotrainval_info.pt',\n",
    "    'word_vecs': base_path + 'data/glove_840B.pt',\n",
    "    'train_from': base_path + 'models/trained_15.pt',\n",
    "    'dataset': base_path + 'data/images',\n",
    "    'gpus': [0],\n",
    "    'top_ans': 1,\n",
    "    'GUI': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-50b8997a07c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import h5py\n",
    "import argparse\n",
    "import json\n",
    "import torchvision.transforms as transforms\n",
    "import sys\n",
    "sys.path.insert(0, \"../\")\n",
    "\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "from dense_coattn.modules import LargeEmbedding\n",
    "from dense_coattn.model import DCN, DCNWithAns, DCNWithRCNN, DCNWithRCNNAns\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.data.path.append(\"/nltk_data\")\n",
    "UNK_WORD = \"<unk>\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((448,448)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def move_to_cuda(tensors, devices=None):\n",
    "    if devices is not None:\n",
    "        if len(devices)>=1:\n",
    "            cuda_tensors = []\n",
    "            for tensor in tensors:\n",
    "                if tensor is not None:\n",
    "                    cuda_tensors.append(tensor.cuda(devices[0],async=True))\n",
    "                else:\n",
    "                    cuda_tensors.append(None)\n",
    "            return tuple(cuda_tensors)\n",
    "    return tensors\n",
    "\n",
    "def get_ques(sentence, word2idx, max_len_ques=14):\n",
    "    processed_sen = word_tokenize(str(sentence).lower())\n",
    "    final_ques = [w if w in word2idx else UNK_WORD for w in processed_sen]\n",
    "    ques = torch.zeros(1, max_len_ques).long()\n",
    "\n",
    "    for i, word in enumerate(final_ques):\n",
    "        if i < max_len_ques:\n",
    "            ques[0, i] = word2idx[word]\n",
    "    ques_mask = ques.ne(0).float()\n",
    "\n",
    "    return ques, ques_mask\n",
    "\n",
    "def get_img(img_path):\n",
    "    return transform(Image.open(img_path).convert(\"RGB\")).unsqueeze(0)\n",
    "\n",
    "def answer(sample, model, idx2ans, opt):\n",
    "    \"\"\"\n",
    "    Generate answers for testing the model.\n",
    "    --------------------\n",
    "    Arguments:\n",
    "        dataloader: dataloader to provide data for the network.\n",
    "        model: our trained network.\n",
    "        idx2ans: set of possible answers.\n",
    "        opt: testing option.\n",
    "    \"\"\"\n",
    "    img, ques, ques_mask = sample\n",
    "    img = torch.tensor(img, requires_grad=False)\n",
    "    ques = torch.tensor(ques, requires_grad=False)\n",
    "    ques_mask = torch.tensor(ques_mask, requires_grad=False)\n",
    "\n",
    "    img, ques, ques_mask = move_to_cuda((img, ques, ques_mask), devices=opt['gpus'])\n",
    "    ques = model.word_embedded(ques)\n",
    "\n",
    "    score = model(img, ques, None, ques_mask, is_train=False)\n",
    "    _, inds = torch.sort(score, dim=1, descending=True)\n",
    "\n",
    "    answer = [idx2ans[inds.data[0, i]] for i in range(opt['top_ans'])]\n",
    "\n",
    "    return answer\n",
    "\n",
    "def load_pretrained_model(opt):\n",
    "    \"\"\"\n",
    "    Generating answers for (image, question) pair in the dataset.\n",
    "    \"\"\"\n",
    "    data_info = torch.load(opt['data_info'])\n",
    "    word2idx = data_info[\"word2idx\"]\n",
    "    idx2word = data_info[\"idx2word\"]\n",
    "    idx2ans = data_info[\"idx2ans\"]\n",
    "\n",
    "    print(\"Building model...\")\n",
    "    word_embedded = LargeEmbedding(len(idx2word), 300, padding_idx=0, devices=opt['gpus'])\n",
    "    word_embedded.load_pretrained_vectors(opt['word_vecs'])\n",
    "\n",
    "    dict_checkpoint = opt['train_from']\n",
    "    if dict_checkpoint:\n",
    "        print(\"Loading model from checkpoint at %s\" % dict_checkpoint)\n",
    "        model = torch.load(dict_checkpoint)\n",
    "\n",
    "    if len(opt['gpus']) >= 1:\n",
    "        model.cuda(opt['gpus'][0])\n",
    "    model.word_embedded = word_embedded\n",
    "    model.eval()\n",
    "\n",
    "    return model, idx2ans, word2idx\n",
    "\n",
    "class Window(Frame):\n",
    "\n",
    "    def __init__(self, master, model, idx2ans, word2idx, opt):\n",
    "        Frame.__init__(self, master)\n",
    "        self.master = master\n",
    "        self.var = StringVar()\n",
    "        self.img_path = None\n",
    "        self.model = model\n",
    "        self.idx2ans = idx2ans\n",
    "        self.word2idx = word2idx\n",
    "        self.opt = opt\n",
    "        self.img_tensor = None\n",
    "        self.answers = None\n",
    "        self.img = None\n",
    "        self.init_window()\n",
    "\n",
    "    def init_window(self):\n",
    "        self.master.title(\"DenseCoAttn demo!\")\n",
    "        self.pack(fill=BOTH, expand=1)\n",
    "\n",
    "        menu = Menu(self.master)\n",
    "        self.master.config(menu=menu)\n",
    "\n",
    "        file = Menu(menu)\n",
    "        file.add_command(label=\"Upload\", command=self.showImg)\n",
    "        file.add_command(label=\"Exit\", command=self.client_exit)\n",
    "        menu.add_cascade(label=\"File\", menu=file)\n",
    "\n",
    "        text = Label(self, text=\"Possible answers:\")\n",
    "        text.place(x=600, y=10)\n",
    "\n",
    "        textbox = Entry(self.master, textTensor=self.var, width=70)\n",
    "        textbox.focus_set()\n",
    "        textbox.pack(pady=10, padx=10)\n",
    "\n",
    "        button = Button(self.master, text=\"Answer\", width=10, command=self.submitQues)\n",
    "        button.pack()\n",
    "\n",
    "    def showImg(self, max_size=500):\n",
    "        img_path = filedialog.askopenfilename(initialdir = \"./\", title = \"Select file\")\n",
    "        print(img_path)\n",
    "\n",
    "        if img_path != \"\":\n",
    "            self.img_tensor = transform(Image.open(img_path).convert(\"RGB\")).unsqueeze(0)\n",
    "            print(self.img_tensor.size())\n",
    "\n",
    "            img_data = Image.open(img_path)\n",
    "            width, height = img_data.size\n",
    "            if width > height:\n",
    "                height = height * max_size / width\n",
    "                width = max_size\n",
    "            else:\n",
    "                width = width * max_size / height\n",
    "                height = max_size\n",
    "            width = int(width)\n",
    "            height = int(height)\n",
    "            render = ImageTk.PhotoImage(img_data.resize((width, height)))\n",
    "\n",
    "            if self.img is not None:\n",
    "                self.img.destroy()\n",
    "            self.img = Label(self, image=render)\n",
    "            self.img.image = render\n",
    "            self.img.place(x=0, y=0)\n",
    "    \n",
    "    def submitQues(self):\n",
    "        if self.answers is not None:\n",
    "            self.answers.destroy()\n",
    "        ques, ques_mask = get_ques(self.var.get(), self.word2idx)\n",
    "        answers = answer((self.img_tensor, ques, ques_mask), self.model, self.idx2ans, self.opt)\n",
    "        self.answers = Label(self, text=\"1. %s\" % tuple(answers))\n",
    "        self.answers.place(x=600, y=50)\n",
    "\n",
    "    def client_exit(self):\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, idx2ans, word2idx = load_pretrained_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt['GUI'] == 1:\n",
    "    root = Tk()\n",
    "    root.geometry(\"800x500\")\n",
    "    app = Window(root, model, idx2ans, word2idx, opt)\n",
    "    root.mainloop()\n",
    "else:\n",
    "    #img_path = input('Test Image Path: ')\n",
    "    #question = input('Question: ')\n",
    "    img_path = base_path + 'data/images/train2014/COCO_train2014_000000000009.jpg'\n",
    "    question = 'How many people?'\n",
    "    if img_path != \"\":\n",
    "        img_tensor = transform(Image.open(img_path).convert(\"RGB\")).unsqueeze(0)\n",
    "        print(img_tensor.size())\n",
    "\n",
    "        img_data = Image.open(img_path)\n",
    "        img_data.show()\n",
    "\n",
    "        ques, ques_mask = get_ques(question, word2idx)\n",
    "        answers = answer((img_tensor, ques, ques_mask), model, idx2ans, opt)\n",
    "        answer = tuple(answers)\n",
    "        print('Answers: ',answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
